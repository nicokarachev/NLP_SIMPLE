{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43010af9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as data\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cd8e60",
   "metadata": {},
   "source": [
    "![MHA](./image/MHA.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2f58a6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        # Ensure that the model dimension (d_model) is divisible by the number of heads\n",
    "        assert d_model % num_heads == 0, \"d_model must be divisible by num_heads\"\n",
    "        \n",
    "        # Initialize dimensions\n",
    "        self.d_model = d_model # Model's dimension\n",
    "        self.num_heads = num_heads # Number of attention heads\n",
    "        self.d_k = d_model // num_heads # Dimension of each head's key, query, and value\n",
    "        \n",
    "        # Linear layers for transforming inputs\n",
    "        self.W_q = nn.Linear(d_model, d_model) # Query transformation\n",
    "        self.W_k = nn.Linear(d_model, d_model) # Key transformation\n",
    "        self.W_v = nn.Linear(d_model, d_model) # Value transformation\n",
    "        self.W_o = nn.Linear(d_model, d_model) # Output transformation\n",
    "        \n",
    "    def scaled_dot_product_attention(self, Q, K, V, mask=None):\n",
    "        # Calculate attention scores\n",
    "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.d_k)\n",
    "        \n",
    "        # Apply mask if provided (useful for preventing attention to certain parts like padding)\n",
    "        if mask is not None:\n",
    "            attn_scores = attn_scores.masked_fill(mask == 0, -1e9)\n",
    "        \n",
    "        # Softmax is applied to obtain attention probabilities\n",
    "        attn_probs = torch.softmax(attn_scores, dim=-1)\n",
    "        \n",
    "        # Multiply by values to obtain the final output\n",
    "        output = torch.matmul(attn_probs, V)\n",
    "        return output\n",
    "        \n",
    "    def split_heads(self, x):\n",
    "        # Reshape the input to have num_heads for multi-head attention\n",
    "        batch_size, seq_length, d_model = x.size()\n",
    "        return x.view(batch_size, seq_length, self.num_heads, self.d_k).transpose(1, 2)\n",
    "        \n",
    "    def combine_heads(self, x):\n",
    "        # Combine the multiple heads back to original shape\n",
    "        batch_size, _, seq_length, d_k = x.size()\n",
    "        return x.transpose(1, 2).contiguous().view(batch_size, seq_length, self.d_model)\n",
    "        \n",
    "    def forward(self, Q, K, V, mask=None):\n",
    "        # Apply linear transformations and split heads\n",
    "        Q = self.split_heads(self.W_q(Q))\n",
    "        K = self.split_heads(self.W_k(K))\n",
    "        V = self.split_heads(self.W_v(V))\n",
    "        \n",
    "        # Perform scaled dot-product attention\n",
    "        attn_output = self.scaled_dot_product_attention(Q, K, V, mask)\n",
    "        \n",
    "        # Combine heads and apply output transformation\n",
    "        output = self.W_o(self.combine_heads(attn_output))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee7a0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super(PositionWiseFeedForward, self).__init__()\n",
    "        self.fc1 = nn.Linear(d_model, d_ff)\n",
    "        self.fc2 = nn.Linear(d_ff, d_model)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(self.relu(self.fc1(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b94d7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_seq_length):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        \n",
    "        pe = torch.zeros(max_seq_length, d_model)\n",
    "        position = torch.arange(0, max_seq_length, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * -(math.log(10000.0) / d_model))\n",
    "        \n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e92fed",
   "metadata": {},
   "source": [
    "![Encoder](./image/encoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8a066fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, mask):\n",
    "        attn_output = self.self_attn(x, x, x, mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm2(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73a1395",
   "metadata": {},
   "source": [
    "![Decoder](./image/decoder.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2792e7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, num_heads, d_ff, dropout):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "        self.self_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.cross_attn = MultiHeadAttention(d_model, num_heads)\n",
    "        self.feed_forward = PositionWiseFeedForward(d_model, d_ff)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "        self.norm3 = nn.LayerNorm(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x, enc_output, src_mask, tgt_mask):\n",
    "        attn_output = self.self_attn(x, x, x, tgt_mask)\n",
    "        x = self.norm1(x + self.dropout(attn_output))\n",
    "        attn_output = self.cross_attn(x, enc_output, enc_output, src_mask)\n",
    "        x = self.norm2(x + self.dropout(attn_output))\n",
    "        ff_output = self.feed_forward(x)\n",
    "        x = self.norm3(x + self.dropout(ff_output))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b86aa84",
   "metadata": {},
   "source": [
    "![Combination Encoder and Decoder](./image/All.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09b4375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder_embedding = nn.Embedding(src_vocab_size, d_model)\n",
    "        self.decoder_embedding = nn.Embedding(tgt_vocab_size, d_model)\n",
    "        self.positional_encoding = PositionalEncoding(d_model, max_seq_length)\n",
    "\n",
    "        self.encoder_layers = nn.ModuleList([EncoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.decoder_layers = nn.ModuleList([DecoderLayer(d_model, num_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "\n",
    "        self.fc = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def generate_mask(self, src, tgt):\n",
    "        src_mask = (src != 0).unsqueeze(1).unsqueeze(2)\n",
    "        tgt_mask = (tgt != 0).unsqueeze(1).unsqueeze(3)\n",
    "        seq_length = tgt.size(1)\n",
    "        nopeak_mask = (1 - torch.triu(torch.ones(1, seq_length, seq_length), diagonal=1)).bool()\n",
    "        tgt_mask = tgt_mask & nopeak_mask\n",
    "        return src_mask, tgt_mask\n",
    "\n",
    "    def forward(self, src, tgt):\n",
    "        src_mask, tgt_mask = self.generate_mask(src, tgt)\n",
    "        src_embedded = self.dropout(self.positional_encoding(self.encoder_embedding(src)))\n",
    "        tgt_embedded = self.dropout(self.positional_encoding(self.decoder_embedding(tgt)))\n",
    "\n",
    "        enc_output = src_embedded\n",
    "        for enc_layer in self.encoder_layers:\n",
    "            enc_output = enc_layer(enc_output, src_mask)\n",
    "\n",
    "        dec_output = tgt_embedded\n",
    "        for dec_layer in self.decoder_layers:\n",
    "            dec_output = dec_layer(dec_output, enc_output, src_mask, tgt_mask)\n",
    "\n",
    "        output = self.fc(dec_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "15498dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_vocab_size = 5000\n",
    "tgt_vocab_size = 5000\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "num_layers = 6\n",
    "d_ff = 2048\n",
    "max_seq_length = 100\n",
    "dropout = 0.1\n",
    "\n",
    "transformer = Transformer(src_vocab_size, tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "\n",
    "# Generate random sample data\n",
    "# src_data = torch.randint(1, src_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)\n",
    "# tgt_data = torch.randint(1, tgt_vocab_size, (64, max_seq_length))  # (batch_size, seq_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "29a31a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "English vocabulary size: 124\n",
      "Chinese vocabulary size: 169\n",
      "English vocabulary: ['<pad>', '<sos>', '<eos>', '<unk>', '\\ufeffhi.', 'hi.', 'run.', 'stop!', 'wait!', 'begin.']\n",
      "Chinese vocabulary: ['<pad>', '<sos>', '<eos>', '<unk>', '嗨', '。', '你', '好', '用', '跑']\n",
      "Source batch (padded):\n",
      "tensor([[  1,   4,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,   5,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,   6,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,   7,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,   8,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,   8,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,   9,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  10,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  11,  12,   2,   0,   0,   0,   0],\n",
      "        [  1,  11,  13,   2,   0,   0,   0,   0],\n",
      "        [  1,  14,  15,   2,   0,   0,   0,   0],\n",
      "        [  1,  16,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  17,  18,   2,   0,   0,   0,   0],\n",
      "        [  1,  17,  18,   2,   0,   0,   0,   0],\n",
      "        [  1,  17,  18,   2,   0,   0,   0,   0],\n",
      "        [  1,  19,  20,   2,   0,   0,   0,   0],\n",
      "        [  1,  21,  22,   2,   0,   0,   0,   0],\n",
      "        [  1,  11,  23,   2,   0,   0,   0,   0],\n",
      "        [  1,  11,  24,   2,   0,   0,   0,   0],\n",
      "        [  1,  11,  24,   2,   0,   0,   0,   0],\n",
      "        [  1,  25,  26,   2,   0,   0,   0,   0],\n",
      "        [  1,  25,  27,   2,   0,   0,   0,   0],\n",
      "        [  1,  28,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  29,  30,   2,   0,   0,   0,   0],\n",
      "        [  1,  29,  30,   2,   0,   0,   0,   0],\n",
      "        [  1,  31,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  31,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  32,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  33,  34,   2,   0,   0,   0,   0],\n",
      "        [  1,  35,  12,   2,   0,   0,   0,   0],\n",
      "        [  1,  36,  37,  38,  39,  40,   2,   0],\n",
      "        [  1,  36,  37,  41,  42,  43,   2,   0],\n",
      "        [  1,  36,  37,  44,  45,  46,   2,   0],\n",
      "        [  1,  36,  47,  48,  49,  50,   2,   0],\n",
      "        [  1,  36,  51,  52,  53,   2,   0,   0],\n",
      "        [  1,  36,  54,  55,  56,  57,   2,   0],\n",
      "        [  1,  36,  58,  48,  55,  59,  60,   2],\n",
      "        [  1,  36,  58,  48,  55,  59,  61,   2],\n",
      "        [  1,  36,  62,  63,  64,  65,   2,   0],\n",
      "        [  1,  36,  62,  66,  67,  68,   2,   0],\n",
      "        [  1,  36,  69,  36,  70,  55,  71,   2],\n",
      "        [  1,  36,  72,  73,  63,  74,   2,   0],\n",
      "        [  1,  36,  72,  73,  63,  74,   2,   0],\n",
      "        [  1,  36,  75,  76,  77,  78,   2,   0],\n",
      "        [  1,  36,  79,  80,  81,   2,   0,   0],\n",
      "        [  1,  36,  82,  83,   2,   0,   0,   0],\n",
      "        [  1,  36,  84,  85,  86,  87,  88,   2],\n",
      "        [  1,  36,  89,  90,  43,   2,   0,   0],\n",
      "        [  1,  36,  91,  92,  73,  93,  94,   2],\n",
      "        [  1,  36,  91,  95,  96,  97,   2,   0],\n",
      "        [  1,  36,  91,  98,  39,  99,   2,   0],\n",
      "        [  1,  36,  91,  38,  39, 100,   2,   0],\n",
      "        [  1, 101,  76, 102, 103,   2,   0,   0],\n",
      "        [  1,  11, 104,  11, 105, 106, 107,   2],\n",
      "        [  1,  11, 104,  11,  58,  55, 108,   2],\n",
      "        [  1,  11, 104,  25, 109,  73, 110,   2],\n",
      "        [  1,  11, 104, 111, 112, 113,   2,   0],\n",
      "        [  1,  11, 104, 114,  37, 115, 116,   2],\n",
      "        [  1,  11, 104, 117, 118, 119,   2,   0],\n",
      "        [  1,  11, 104,  35, 120,  33,  34,   2],\n",
      "        [  1,  11, 104, 121,  39, 122,   2,   0],\n",
      "        [  1,  11, 104,  90,  66,  55, 123,   2]])\n",
      "Target batch (padded):\n",
      "tensor([[  1,   4,   5,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   6,   7,   5,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   6,   8,   9,  10,   5,   2,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  11,  12,  13,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  14,  14,  13,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  14,  15,  16,  13,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  17,  18,  13,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   6,   7,   5,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  20,  20,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  21,  22,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  23,  24,  25,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  26,  27,  28,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  29,  30,  22,  31,  32,  33,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  34,  22,  35,  33,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   6,  34,  22,  35,  33,   2,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  36,   9,  22,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  37,  38,  39,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  29,  30,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  40,  41,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  23,  42,  22,   5,   2,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  43,  44,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  45,  46,  47,  39,  22,   5,   2,   0,   0,   0,   0],\n",
      "        [  1,  48,  49,   5,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  23,  50,  51,  13,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  31,  52,  13,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  53,  10,  33,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,   6,  54,  55,  33,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  56,  56,  13,   2,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  20,  20,  25,   5,   2,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  19,  57,  39,  20,  20,   5,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  58,  59,  49,  60,  61,  10,  62,  63,   5,   2,   0,   0],\n",
      "        [  1,  58,  64,  65,  66,  65,  67,  68,  69,   5,   2,   0,   0],\n",
      "        [  1,  58,  23,  70,  71,  72,  73,   5,   2,   0,   0,   0,   0],\n",
      "        [  1,  58,  74,  75,  76,  77,  78,  36,  22,   5,   2,   0,   0],\n",
      "        [  1,  58,  76,  79,  80,  81,  82,  83,   5,   2,   0,   0,   0],\n",
      "        [  1,  58,  10,  84,  85,  86,  87,  88,   5,   2,   0,   0,   0],\n",
      "        [  1,  58,  89,  36,  90,  22,  91,  92,  93,  62,   5,   2,   0],\n",
      "        [  1,  58,  89,  36,  90,  22,  15,  94,  92,  62,  63,   5,   2],\n",
      "        [  1,  58,  95,  55,  96,  97,  98,  99, 100,  22,   5,   2,   0],\n",
      "        [  1,  58,  15,  55,  71,  84, 101,  22,   5,   2,   0,   0,   0],\n",
      "        [  1,  58, 102,  58, 103, 104,  22,   5,   2,   0,   0,   0,   0],\n",
      "        [  1,  58, 105,  47,  39,  23, 106, 107,   5,   2,   0,   0,   0],\n",
      "        [  1,  58, 105,  47, 108,  23, 109, 110,   5,   2,   0,   0,   0],\n",
      "        [  1,  58, 111,  19, 105,  58,  10, 112, 113,   5,   2,   0,   0],\n",
      "        [  1,  58, 114, 115, 116,  10,  86,   7,   5,   2,   0,   0,   0],\n",
      "        [  1,  58, 117, 118, 119, 117,   2,   0,   0,   0,   0,   0,   0],\n",
      "        [  1,  58, 120, 121,  22,  19,  10, 122,   5,   2,   0,   0,   0],\n",
      "        [  1,  58,  64,  65,  22, 123,   6,   5,   2,   0,   0,   0,   0],\n",
      "        [  1,  58,  66, 124,  41, 125,   5,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  58, 126, 127, 128, 129,   5,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  58,  84,  65, 130, 131,   5,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  58,  59, 132, 133, 134,  62,   5,   2,   0,   0,   0,   0],\n",
      "        [  1, 135, 136,  19, 137, 138, 139, 140,   5,   2,   0,   0,   0],\n",
      "        [  1,  19, 141,  19, 142, 143, 144, 145,  22,   5,   2,   0,   0],\n",
      "        [  1,  19, 105,  19, 146,  22, 147, 148,   5,   2,   0,   0,   0],\n",
      "        [  1,  19,  50, 124, 149,  22,   5,   2,   0,   0,   0,   0,   0],\n",
      "        [  1,  19, 150,  89,  19,  90, 143, 151,  22,   5,   2,   0,   0],\n",
      "        [  1,  19, 150,  89, 152, 153,  86, 154,   5,   2,   0,   0,   0],\n",
      "        [  1,  19, 150,  89, 155,  23, 156, 157, 158,   5,   2,   0,   0],\n",
      "        [  1,  19, 105,  19, 159, 160, 161, 161,   5,   2,   0,   0,   0],\n",
      "        [  1,  19, 162, 163,  19,  57,  32, 164, 165,   5,   2,   0,   0],\n",
      "        [  1,  19, 166, 143,   6, 167, 168,  22,   5,   2,   0,   0,   0]])\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "class Vocab:\n",
    "    def __init__(self, tokens, min_freq=1, specials=[\"<pad>\", \"<sos>\", \"<eos>\", \"<unk>\"]):\n",
    "        counter = Counter(token for sent in tokens for token in sent)\n",
    "        self.itos = specials + [tok for tok, freq in counter.items() if freq >= min_freq and tok not in specials]\n",
    "        self.stoi = {tok: i for i, tok in enumerate(self.itos)}\n",
    "\n",
    "    def encode(self, tokens):\n",
    "        return [self.stoi.get(tok, self.stoi[\"<unk>\"]) for tok in tokens]\n",
    "\n",
    "    def decode(self, ids):\n",
    "        return [self.itos[i] for i in ids]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.itos)\n",
    "\n",
    "# Example usage\n",
    "def tokenize_en(text): return text.lower().split()\n",
    "def tokenize_zh(text): return list(text.strip())\n",
    "\n",
    "# Load and parse the dataset\n",
    "def load_parallel_data(path, max_samples=10000):\n",
    "    src_sentences = []\n",
    "    tgt_sentences = []\n",
    "    with open(path, encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            if '\\t' not in line: continue\n",
    "            eng, zh, *_ = line.strip().split('\\t')\n",
    "            src_sentences.append(eng.lower())\n",
    "            tgt_sentences.append(zh)\n",
    "            if len(src_sentences) >= max_samples:\n",
    "                break\n",
    "    return src_sentences, tgt_sentences\n",
    "\n",
    "eng_texts, zh_texts = load_parallel_data(\"datasets/cmn.txt\", max_samples=5000)\n",
    "\n",
    "# def tokenize_en(sentence):\n",
    "#     return sentence.lower().split()\n",
    "\n",
    "# def tokenize_zh(sentence):\n",
    "#     return list(sentence.strip())  # Character-level\n",
    "\n",
    "en_tokens = [tokenize_en(s) for s in eng_texts]\n",
    "zh_tokens = [tokenize_zh(s) for s in zh_texts]\n",
    "\n",
    "\n",
    "en_vocab = Vocab(en_tokens)\n",
    "zh_vocab = Vocab(zh_tokens)\n",
    "\n",
    "print(f\"English vocabulary size: {len(en_vocab)}\")\n",
    "print(f\"Chinese vocabulary size: {len(zh_vocab)}\")\n",
    "print(f\"English vocabulary: {en_vocab.itos[:10]}\")\n",
    "print(f\"Chinese vocabulary: {zh_vocab.itos[:10]}\")\n",
    "\n",
    "def pad_batch(batch, pad_id):\n",
    "    max_len = max(len(x) for x in batch)\n",
    "    return torch.tensor([x + [pad_id] * (max_len - len(x)) for x in batch])\n",
    "\n",
    "# src_vocab = build_vocab(eng_texts, tokenize_en)\n",
    "# tgt_vocab = build_vocab(zh_texts, tokenize_zh)\n",
    "\n",
    "src_batch = [en_vocab.encode([\"<sos>\"] + tokenize_en(s) + [\"<eos>\"]) for s in eng_texts]\n",
    "tgt_batch = [zh_vocab.encode([\"<sos>\"] + tokenize_zh(s) + [\"<eos>\"]) for s in zh_texts]\n",
    "\n",
    "src_batch_padded = pad_batch(src_batch, en_vocab.stoi[\"<pad>\"])\n",
    "tgt_batch_padded = pad_batch(tgt_batch, zh_vocab.stoi[\"<pad>\"])\n",
    "\n",
    "print(\"Source batch (padded):\")\n",
    "print(src_batch_padded)\n",
    "print(\"Target batch (padded):\")\n",
    "print(tgt_batch_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bf76092",
   "metadata": {},
   "outputs": [],
   "source": [
    "src_data = src_batch_padded\n",
    "tgt_data = tgt_batch_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7be1e95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and validation sets\n",
    "train_ratio = 0.9\n",
    "train_size = int(len(src_data) * train_ratio)\n",
    "\n",
    "src_train = src_data[:train_size]\n",
    "tgt_train = tgt_data[:train_size]\n",
    "src_val = src_data[train_size:]\n",
    "tgt_val = tgt_data[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "882b8da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = TensorDataset(src_train, tgt_train)\n",
    "val_dataset = TensorDataset(src_val, tgt_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf77de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Training Loss: 7.9225\n",
      "Epoch 2, Training Loss: 6.3125\n",
      "Epoch 3, Training Loss: 5.9099\n",
      "Epoch 4, Training Loss: 5.5422\n",
      "Epoch 5, Training Loss: 5.2377\n",
      "Epoch 6, Training Loss: 4.9037\n",
      "Epoch 7, Training Loss: 4.5602\n",
      "Epoch 8, Training Loss: 4.3241\n",
      "Epoch 9, Training Loss: 4.0037\n",
      "Epoch 10, Training Loss: 3.7141\n",
      "Epoch 11, Training Loss: 3.4566\n",
      "Epoch 12, Training Loss: 3.1487\n",
      "Epoch 13, Training Loss: 2.9300\n",
      "Epoch 14, Training Loss: 2.6616\n",
      "Epoch 15, Training Loss: 2.4866\n",
      "Epoch 16, Training Loss: 2.2357\n",
      "Epoch 17, Training Loss: 2.0837\n",
      "Epoch 18, Training Loss: 1.8847\n",
      "Epoch 19, Training Loss: 1.7052\n",
      "Epoch 20, Training Loss: 1.5328\n",
      "Epoch 21, Training Loss: 1.3942\n",
      "Epoch 22, Training Loss: 1.2398\n",
      "Epoch 23, Training Loss: 1.1321\n",
      "Epoch 24, Training Loss: 1.0151\n",
      "Epoch 25, Training Loss: 0.9084\n",
      "Epoch 26, Training Loss: 0.8183\n",
      "Epoch 27, Training Loss: 0.7354\n",
      "Epoch 28, Training Loss: 0.6491\n",
      "Epoch 29, Training Loss: 0.5919\n",
      "Epoch 30, Training Loss: 0.5383\n",
      "Epoch 31, Training Loss: 0.4801\n",
      "Epoch 32, Training Loss: 0.4227\n",
      "Epoch 33, Training Loss: 0.3889\n",
      "Epoch 34, Training Loss: 0.3485\n",
      "Epoch 35, Training Loss: 0.3136\n",
      "Epoch 36, Training Loss: 0.2904\n",
      "Epoch 37, Training Loss: 0.2658\n",
      "Epoch 38, Training Loss: 0.2426\n",
      "Epoch 39, Training Loss: 0.2252\n",
      "Epoch 40, Training Loss: 0.2077\n",
      "Epoch 41, Training Loss: 0.1885\n",
      "Epoch 42, Training Loss: 0.1921\n",
      "Epoch 43, Training Loss: 0.1750\n",
      "Epoch 44, Training Loss: 0.1838\n",
      "Epoch 45, Training Loss: 0.1638\n",
      "Epoch 46, Training Loss: 0.1463\n",
      "Epoch 47, Training Loss: 0.1483\n",
      "Epoch 48, Training Loss: 0.1358\n",
      "Epoch 49, Training Loss: 0.1381\n",
      "Epoch 50, Training Loss: 0.1151\n",
      "Epoch 51, Training Loss: 0.1173\n",
      "Epoch 52, Training Loss: 0.1122\n",
      "Epoch 53, Training Loss: 0.1222\n",
      "Epoch 54, Training Loss: 0.1012\n",
      "Epoch 55, Training Loss: 0.1374\n",
      "Epoch 56, Training Loss: 0.1052\n",
      "Epoch 57, Training Loss: 0.1146\n",
      "Epoch 58, Training Loss: 0.0980\n",
      "Epoch 59, Training Loss: 0.1034\n",
      "Epoch 60, Training Loss: 0.0899\n",
      "Epoch 61, Training Loss: 0.0869\n",
      "Epoch 62, Training Loss: 0.0807\n",
      "Epoch 63, Training Loss: 0.0895\n",
      "Epoch 64, Training Loss: 0.0862\n",
      "Epoch 65, Training Loss: 0.0785\n",
      "Epoch 66, Training Loss: 0.0781\n",
      "Epoch 67, Training Loss: 0.0738\n",
      "Epoch 68, Training Loss: 0.0715\n",
      "Epoch 69, Training Loss: 0.0695\n",
      "Epoch 70, Training Loss: 0.0705\n",
      "Epoch 71, Training Loss: 0.0670\n",
      "Epoch 72, Training Loss: 0.0659\n",
      "Epoch 73, Training Loss: 0.0692\n",
      "Epoch 74, Training Loss: 0.0590\n",
      "Epoch 75, Training Loss: 0.0615\n",
      "Epoch 76, Training Loss: 0.0704\n",
      "Epoch 77, Training Loss: 0.0579\n",
      "Epoch 78, Training Loss: 0.0660\n",
      "Epoch 79, Training Loss: 0.0549\n",
      "Epoch 80, Training Loss: 0.0606\n",
      "Epoch 81, Training Loss: 0.0644\n",
      "Epoch 82, Training Loss: 0.0589\n",
      "Epoch 83, Training Loss: 0.0592\n",
      "Epoch 84, Training Loss: 0.0575\n",
      "Epoch 85, Training Loss: 0.0541\n",
      "Epoch 86, Training Loss: 0.0608\n",
      "Epoch 87, Training Loss: 0.0587\n",
      "Epoch 88, Training Loss: 0.0545\n",
      "Epoch 89, Training Loss: 0.0538\n",
      "Epoch 90, Training Loss: 0.0697\n",
      "Epoch 91, Training Loss: 0.0705\n",
      "Epoch 92, Training Loss: 0.0551\n",
      "Epoch 93, Training Loss: 0.0854\n",
      "Epoch 94, Training Loss: 0.0676\n",
      "Epoch 95, Training Loss: 0.0566\n",
      "Epoch 96, Training Loss: 0.0783\n",
      "Epoch 97, Training Loss: 0.0597\n",
      "Epoch 98, Training Loss: 0.0809\n",
      "Epoch 99, Training Loss: 0.0562\n",
      "Epoch 100, Training Loss: 0.0735\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index=en_vocab.stoi[\"<pad>\"])\n",
    "# optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.0001, betas=(0.9, 0.98), eps=1e-9)\n",
    "transformer.train()\n",
    "\n",
    "for epoch in range(100):\n",
    "    total_loss = 0\n",
    "    for src_batch, tgt_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = transformer(src_batch, tgt_batch[:, :-1])\n",
    "        loss = criterion(output.reshape(-1, tgt_vocab_size), tgt_batch[:, 1:].reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}, Training Loss: {avg_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d6d569a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 5.9935\n"
     ]
    }
   ],
   "source": [
    "transformer.eval()\n",
    "val_loss = 0\n",
    "with torch.no_grad():\n",
    "    for src_batch, tgt_batch in val_loader:\n",
    "        output = transformer(src_batch, tgt_batch[:, :-1])\n",
    "        loss = criterion(output.reshape(-1, tgt_vocab_size), tgt_batch[:, 1:].reshape(-1))\n",
    "        val_loss += loss.item()\n",
    "\n",
    "avg_val_loss = val_loss / len(val_loader)\n",
    "print(f\"Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "da0dd7bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, transformer, en_vocab, zh_vocab, max_len=50, device='cpu'):\n",
    "    transformer.eval()\n",
    "    \n",
    "    # Tokenize and encode the English sentence\n",
    "    tokens = [\"<sos>\"] + tokenize_en(sentence) + [\"<eos>\"]\n",
    "    src_ids = en_vocab.encode(tokens)\n",
    "    src_tensor = torch.tensor(src_ids).unsqueeze(0).to(device)  # shape: (1, src_len)\n",
    "\n",
    "    # Start decoding with <sos>\n",
    "    tgt_ids = [zh_vocab.stoi[\"<sos>\"]]\n",
    "    for _ in range(max_len):\n",
    "        tgt_tensor = torch.tensor(tgt_ids).unsqueeze(0).to(device)  # shape: (1, tgt_len)\n",
    "        with torch.no_grad():\n",
    "            output = transformer(src_tensor, tgt_tensor)  # (1, tgt_len, vocab_size)\n",
    "        \n",
    "        next_token = output[0, -1].argmax(dim=-1).item()\n",
    "        tgt_ids.append(next_token)\n",
    "        \n",
    "        if next_token == zh_vocab.stoi[\"<eos>\"]:\n",
    "            break\n",
    "\n",
    "    # Decode IDs to Chinese characters\n",
    "    translated_tokens = zh_vocab.decode(tgt_ids[1:-1])  # remove <sos> and <eos>\n",
    "    return ''.join(translated_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1aea9c75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wait! → 等一下！\n"
     ]
    }
   ],
   "source": [
    "example_sentence = \"Wait!\"\n",
    "translation = translate_sentence(example_sentence, transformer, en_vocab, zh_vocab)\n",
    "print(f\"{example_sentence} → {translation}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab5fb1b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.10.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
